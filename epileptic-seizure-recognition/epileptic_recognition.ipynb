{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9',\n",
       "       ...\n",
       "       'X170', 'X171', 'X172', 'X173', 'X174', 'X175', 'X176', 'X177', 'X178',\n",
       "       'y'],\n",
       "      dtype='object', length=180)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Dataset.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:, \"X1\":'X178']\n",
    "features = features.apply(lambda x: x.to_numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(pd.Series([pd.Series(i) for i in df.loc[:, 'X1':'X178'].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catch22(n_jobs=8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.transformations.panel.catch22 import Catch22\n",
    "\n",
    "ct22 = Catch22(n_jobs=4)\n",
    "ct22.fit(features, df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_22 = ct22.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-26.000000</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.814607</td>\n",
       "      <td>-0.011236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8508.861901</td>\n",
       "      <td>0.466330</td>\n",
       "      <td>69.664521</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.732131</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.117763</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290.100006</td>\n",
       "      <td>401.549988</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-0.095506</td>\n",
       "      <td>-0.230337</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>209916.516743</td>\n",
       "      <td>0.147262</td>\n",
       "      <td>259.886855</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.519348</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.123658</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23.000000</td>\n",
       "      <td>-33.299999</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1708.578962</td>\n",
       "      <td>0.269981</td>\n",
       "      <td>29.774771</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.699354</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.095719</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-63.500000</td>\n",
       "      <td>-67.650002</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>205.747035</td>\n",
       "      <td>0.368155</td>\n",
       "      <td>11.966560</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.773506</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.080036</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.699999</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>-0.764045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>984.968035</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>31.206047</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.773262</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.097457</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1     2         3         4    5     6              7   \\\n",
       "0  -26.000000   50.500000  17.0 -0.814607 -0.011236  4.0   7.0    8508.861901   \n",
       "1  290.100006  401.549988  42.0 -0.095506 -0.230337  6.0  18.0  209916.516743   \n",
       "2  -23.000000  -33.299999  15.0  0.758427  0.067416  4.0   9.0    1708.578962   \n",
       "3  -63.500000  -67.650002  19.0  0.000000  0.005618  4.0   6.0     205.747035   \n",
       "4   23.699999    5.600000  20.0  0.230337 -0.764045  3.0   5.0     984.968035   \n",
       "\n",
       "         8           9   ...    12        13    14        15     16        17  \\\n",
       "0  0.466330   69.664521  ...   3.0  0.994350   9.0  1.732131  0.600  0.117763   \n",
       "1  0.147262  259.886855  ...  10.0  0.977401  18.0  1.519348  0.250  0.123658   \n",
       "2  0.269981   29.774771  ...   6.0  0.977401   9.0  1.699354  0.375  0.095719   \n",
       "3  0.368155   11.966560  ...   6.0  0.949153   7.0  1.773506  0.500  0.080036   \n",
       "4  0.392699   31.206047  ...   4.0  0.971751  11.0  1.773262  0.060  0.097457   \n",
       "\n",
       "         18        19        20    21  \n",
       "0  0.853659  0.170732  0.000544  12.0  \n",
       "1  0.658537  0.317073  0.006803  48.0  \n",
       "2  0.731707  0.195122  0.011708  19.0  \n",
       "3  0.731707  0.219512  0.003171  13.0  \n",
       "4  0.780488  0.170732  0.111111   7.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_22.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform features by MINImally RandOm Convolutional KErnel Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.panel.rocket import MiniRocket\n",
    "\n",
    "mr = MiniRocket(num_kernels=1000, n_jobs=1)\n",
    "# features = [mr.fit_transform(i) for i in features]\n",
    "transformed_mr = mr.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>914</th>\n",
       "      <th>915</th>\n",
       "      <th>916</th>\n",
       "      <th>917</th>\n",
       "      <th>918</th>\n",
       "      <th>919</th>\n",
       "      <th>920</th>\n",
       "      <th>921</th>\n",
       "      <th>922</th>\n",
       "      <th>923</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.805882</td>\n",
       "      <td>0.405882</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>0.376404</td>\n",
       "      <td>0.594118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629214</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.421348</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>0.688235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.488764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.471910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.91573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516854</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230337</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.535294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241176</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241573</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.688235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.888235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.168539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.151685</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.960674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117978</td>\n",
       "      <td>0.723529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 924 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.370787  0.741573  0.185393  0.558824  0.805882  0.405882  0.702247   \n",
       "1  0.421348  0.758427  0.292135  0.635294  0.770588  0.423529  0.730337   \n",
       "2  0.230337  0.977528  0.011236  0.535294  1.000000  0.241176  0.853933   \n",
       "3  0.016854  1.000000  0.005618  0.688235  1.000000  0.000000  0.988764   \n",
       "4  0.151685  0.983146  0.011236  0.588235  0.982353  0.123529  0.960674   \n",
       "\n",
       "        7         8         9    ...       914  915       916  917       918  \\\n",
       "0  0.084270  0.376404  0.594118  ...  0.337079  0.0  0.348315  0.0  0.241573   \n",
       "1  0.213483  0.438202  0.688235  ...  0.573034  1.0  0.488764  1.0  0.471910   \n",
       "2  0.000000  0.241573  0.658824  ...  0.297753  1.0  0.286517  1.0  0.084270   \n",
       "3  0.000000  0.022472  0.888235  ...  0.185393  1.0  0.168539  1.0  0.022472   \n",
       "4  0.000000  0.117978  0.723529  ...  0.443820  1.0  0.235955  1.0  0.061798   \n",
       "\n",
       "   919      920  921       922  923  \n",
       "0  0.0  1.00000  0.0  0.629214  1.0  \n",
       "1  1.0  0.91573  1.0  0.516854  1.0  \n",
       "2  1.0  1.00000  0.0  0.730337  1.0  \n",
       "3  1.0  1.00000  0.0  0.691011  1.0  \n",
       "4  0.0  1.00000  0.0  0.910112  1.0  \n",
       "\n",
       "[5 rows x 924 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_mr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform labels (1 - have epileptic seizure, 0 - don't have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_transformer(label):\n",
    "    return 1 if label == 1 else 0\n",
    "\n",
    "labels = df['y'].apply(labels_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select train and test data for transformed by MiniRocket data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_mr, labels, random_state=1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rc = RandomForestClassifier(n_estimators=1000)\n",
    "rc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864347826086957"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, rc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4837350\ttotal: 223ms\tremaining: 10.9s\n",
      "1:\tlearn: 0.3469505\ttotal: 256ms\tremaining: 6.16s\n",
      "2:\tlearn: 0.2659528\ttotal: 290ms\tremaining: 4.54s\n",
      "3:\tlearn: 0.2105653\ttotal: 325ms\tremaining: 3.73s\n",
      "4:\tlearn: 0.1662268\ttotal: 358ms\tremaining: 3.23s\n",
      "5:\tlearn: 0.1293833\ttotal: 392ms\tremaining: 2.87s\n",
      "6:\tlearn: 0.1002352\ttotal: 424ms\tremaining: 2.6s\n",
      "7:\tlearn: 0.0837120\ttotal: 458ms\tremaining: 2.41s\n",
      "8:\tlearn: 0.0733335\ttotal: 494ms\tremaining: 2.25s\n",
      "9:\tlearn: 0.0641682\ttotal: 531ms\tremaining: 2.12s\n",
      "10:\tlearn: 0.0571338\ttotal: 567ms\tremaining: 2.01s\n",
      "11:\tlearn: 0.0511185\ttotal: 600ms\tremaining: 1.9s\n",
      "12:\tlearn: 0.0476150\ttotal: 641ms\tremaining: 1.82s\n",
      "13:\tlearn: 0.0446337\ttotal: 678ms\tremaining: 1.74s\n",
      "14:\tlearn: 0.0418591\ttotal: 712ms\tremaining: 1.66s\n",
      "15:\tlearn: 0.0402690\ttotal: 745ms\tremaining: 1.58s\n",
      "16:\tlearn: 0.0377733\ttotal: 780ms\tremaining: 1.51s\n",
      "17:\tlearn: 0.0357072\ttotal: 819ms\tremaining: 1.46s\n",
      "18:\tlearn: 0.0353935\ttotal: 876ms\tremaining: 1.43s\n",
      "19:\tlearn: 0.0332471\ttotal: 921ms\tremaining: 1.38s\n",
      "20:\tlearn: 0.0316764\ttotal: 957ms\tremaining: 1.32s\n",
      "21:\tlearn: 0.0315984\ttotal: 990ms\tremaining: 1.26s\n",
      "22:\tlearn: 0.0314986\ttotal: 1.02s\tremaining: 1.2s\n",
      "23:\tlearn: 0.0310328\ttotal: 1.05s\tremaining: 1.14s\n",
      "24:\tlearn: 0.0309335\ttotal: 1.09s\tremaining: 1.09s\n",
      "25:\tlearn: 0.0308488\ttotal: 1.12s\tremaining: 1.04s\n",
      "26:\tlearn: 0.0307933\ttotal: 1.16s\tremaining: 988ms\n",
      "27:\tlearn: 0.0307161\ttotal: 1.19s\tremaining: 936ms\n",
      "28:\tlearn: 0.0295037\ttotal: 1.23s\tremaining: 887ms\n",
      "29:\tlearn: 0.0293325\ttotal: 1.26s\tremaining: 840ms\n",
      "30:\tlearn: 0.0292578\ttotal: 1.3s\tremaining: 796ms\n",
      "31:\tlearn: 0.0281452\ttotal: 1.34s\tremaining: 757ms\n",
      "32:\tlearn: 0.0277746\ttotal: 1.38s\tremaining: 711ms\n",
      "33:\tlearn: 0.0276810\ttotal: 1.44s\tremaining: 679ms\n",
      "34:\tlearn: 0.0264051\ttotal: 1.49s\tremaining: 636ms\n",
      "35:\tlearn: 0.0263631\ttotal: 1.52s\tremaining: 591ms\n",
      "36:\tlearn: 0.0262971\ttotal: 1.55s\tremaining: 544ms\n",
      "37:\tlearn: 0.0261023\ttotal: 1.58s\tremaining: 499ms\n",
      "38:\tlearn: 0.0260727\ttotal: 1.61s\tremaining: 454ms\n",
      "39:\tlearn: 0.0255562\ttotal: 1.64s\tremaining: 410ms\n",
      "40:\tlearn: 0.0254988\ttotal: 1.67s\tremaining: 367ms\n",
      "41:\tlearn: 0.0247120\ttotal: 1.71s\tremaining: 325ms\n",
      "42:\tlearn: 0.0244768\ttotal: 1.74s\tremaining: 283ms\n",
      "43:\tlearn: 0.0244499\ttotal: 1.77s\tremaining: 241ms\n",
      "44:\tlearn: 0.0241714\ttotal: 1.8s\tremaining: 201ms\n",
      "45:\tlearn: 0.0237572\ttotal: 1.84s\tremaining: 160ms\n",
      "46:\tlearn: 0.0237068\ttotal: 1.88s\tremaining: 120ms\n",
      "47:\tlearn: 0.0233043\ttotal: 1.92s\tremaining: 80.1ms\n",
      "48:\tlearn: 0.0229840\ttotal: 1.96s\tremaining: 40ms\n",
      "49:\tlearn: 0.0226272\ttotal: 2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1e122aff700>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cb = CatBoostClassifier(iterations=50,\n",
    "                        learning_rate=0.1)\n",
    "\n",
    "cb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864347826086957"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, cb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    dense_layer = keras.layers.Dense(256, activation=\"relu\")(input_layer)\n",
    "    \n",
    "    dense_layer = keras.layers.Dense(128, activation=\"relu\")(dense_layer)\n",
    "\n",
    "    dense_layer = keras.layers.Dense(32, activation=\"relu\")(dense_layer)\n",
    "    \n",
    "    output_layer = keras.layers.Dense(2, activation=\"softmax\")(dense_layer)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model = make_model(input_shape=X_train.iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "216/216 [==============================] - 2s 4ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.0639 - val_sparse_categorical_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.0556 - val_sparse_categorical_accuracy: 0.9838 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9699 - val_loss: 0.0549 - val_sparse_categorical_accuracy: 0.9780 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0711 - sparse_categorical_accuracy: 0.9735 - val_loss: 0.0524 - val_sparse_categorical_accuracy: 0.9797 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9749 - val_loss: 0.0520 - val_sparse_categorical_accuracy: 0.9797 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0569 - val_sparse_categorical_accuracy: 0.9733 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 0.9826 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.0496 - val_sparse_categorical_accuracy: 0.9797 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0572 - sparse_categorical_accuracy: 0.9797 - val_loss: 0.0478 - val_sparse_categorical_accuracy: 0.9814 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0518 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0455 - val_sparse_categorical_accuracy: 0.9826 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9759 - val_loss: 0.0462 - val_sparse_categorical_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.0471 - val_sparse_categorical_accuracy: 0.9826 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.0473 - val_sparse_categorical_accuracy: 0.9832 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0516 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.0683 - val_sparse_categorical_accuracy: 0.9757 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0445 - val_sparse_categorical_accuracy: 0.9849 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0504 - val_sparse_categorical_accuracy: 0.9849 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0473 - val_sparse_categorical_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9838 - val_loss: 0.0485 - val_sparse_categorical_accuracy: 0.9803 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.9780 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0447 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0364 - val_sparse_categorical_accuracy: 0.9861 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0449 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.0377 - val_sparse_categorical_accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0413 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0406 - val_sparse_categorical_accuracy: 0.9872 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0399 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.0353 - val_sparse_categorical_accuracy: 0.9872 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0424 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.0353 - val_sparse_categorical_accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.0569 - val_sparse_categorical_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0513 - val_sparse_categorical_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0345 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0412 - val_sparse_categorical_accuracy: 0.9855 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0385 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.0352 - val_sparse_categorical_accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.0492 - val_sparse_categorical_accuracy: 0.9814 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0331 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.0333 - val_sparse_categorical_accuracy: 0.9872 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0329 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.0322 - val_sparse_categorical_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0411 - val_sparse_categorical_accuracy: 0.9867 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0306 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0455 - val_sparse_categorical_accuracy: 0.9814 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0333 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.0498 - val_sparse_categorical_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0329 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.0415 - val_sparse_categorical_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0267 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0274 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0327 - val_sparse_categorical_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0490 - val_sparse_categorical_accuracy: 0.9838 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0311 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.0321 - val_sparse_categorical_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0278 - sparse_categorical_accuracy: 0.9890 - val_loss: 0.0293 - val_sparse_categorical_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0345 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9838 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0360 - val_sparse_categorical_accuracy: 0.9832 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0298 - val_sparse_categorical_accuracy: 0.9896 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0271 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0258 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0270 - val_sparse_categorical_accuracy: 0.9896 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.0411 - val_sparse_categorical_accuracy: 0.9861 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.0239 - val_sparse_categorical_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0261 - val_sparse_categorical_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0228 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0237 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0314 - val_sparse_categorical_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.0305 - val_sparse_categorical_accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0251 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0341 - val_sparse_categorical_accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0241 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0296 - val_sparse_categorical_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0234 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9896 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9896 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0196 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.0290 - val_sparse_categorical_accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0337 - val_sparse_categorical_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0186 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0240 - val_sparse_categorical_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0170 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0243 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.0302 - val_sparse_categorical_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0276 - val_sparse_categorical_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 0.0178 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0217 - val_sparse_categorical_accuracy: 0.9925 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.0215 - val_sparse_categorical_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0198 - val_sparse_categorical_accuracy: 0.9919 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0554 - val_sparse_categorical_accuracy: 0.9814 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0283 - val_sparse_categorical_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0234 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0221 - val_sparse_categorical_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.0221 - val_sparse_categorical_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0537 - val_sparse_categorical_accuracy: 0.9780 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0177 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9872 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0143 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.0393 - val_sparse_categorical_accuracy: 0.9861 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0184 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0310 - val_sparse_categorical_accuracy: 0.9872 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0227 - val_sparse_categorical_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0184 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0281 - val_sparse_categorical_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0125 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0334 - val_sparse_categorical_accuracy: 0.9838 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0144 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.0276 - val_sparse_categorical_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0265 - val_sparse_categorical_accuracy: 0.9930 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9919 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0169 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0223 - val_sparse_categorical_accuracy: 0.9919 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.0240 - val_sparse_categorical_accuracy: 0.9919 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0303 - val_sparse_categorical_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0518 - val_sparse_categorical_accuracy: 0.9896 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0316 - val_sparse_categorical_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0286 - val_sparse_categorical_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0334 - val_sparse_categorical_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0254 - val_sparse_categorical_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0262 - val_sparse_categorical_accuracy: 0.9901 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0319 - val_sparse_categorical_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9913 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0320 - val_sparse_categorical_accuracy: 0.9930 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0284 - val_sparse_categorical_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0308 - val_sparse_categorical_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0351 - val_sparse_categorical_accuracy: 0.9901 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0496 - val_sparse_categorical_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0285 - val_sparse_categorical_accuracy: 0.9930 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0206 - val_sparse_categorical_accuracy: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0285 - val_sparse_categorical_accuracy: 0.9913 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0297 - val_sparse_categorical_accuracy: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0284 - val_sparse_categorical_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 111/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0288 - val_sparse_categorical_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 112/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 0.9843 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0376 - val_sparse_categorical_accuracy: 0.9913 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0343 - val_sparse_categorical_accuracy: 0.9913 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0397 - val_sparse_categorical_accuracy: 0.9907 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0374 - val_sparse_categorical_accuracy: 0.9901 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0315 - val_sparse_categorical_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0426 - val_sparse_categorical_accuracy: 0.9907 - lr: 2.5000e-04\n",
      "Epoch 118: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 1ms/step - loss: 0.0283 - sparse_categorical_accuracy: 0.9899\n",
      "Test accuracy 0.9899130463600159\n",
      "Test loss 0.028260257095098495\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_model.h5\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select train/test data from catch22 features selected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(from_2d_array_to_nested(transformed_22), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6914782608695652"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "\n",
    "rtc = RocketClassifier(num_kernels=1000)\n",
    "\n",
    "rtc.fit(train_X, train_y)\n",
    "accuracy_score(y_test, rtc.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4947423\ttotal: 4.16ms\tremaining: 204ms\n",
      "1:\tlearn: 0.3440368\ttotal: 8.3ms\tremaining: 199ms\n",
      "2:\tlearn: 0.2781930\ttotal: 12.3ms\tremaining: 193ms\n",
      "3:\tlearn: 0.2254799\ttotal: 16.6ms\tremaining: 191ms\n",
      "4:\tlearn: 0.1789705\ttotal: 20.7ms\tremaining: 186ms\n",
      "5:\tlearn: 0.1430847\ttotal: 24.8ms\tremaining: 182ms\n",
      "6:\tlearn: 0.1171341\ttotal: 28.9ms\tremaining: 178ms\n",
      "7:\tlearn: 0.1035416\ttotal: 33ms\tremaining: 173ms\n",
      "8:\tlearn: 0.0891683\ttotal: 37.1ms\tremaining: 169ms\n",
      "9:\tlearn: 0.0795961\ttotal: 41.4ms\tremaining: 166ms\n",
      "10:\tlearn: 0.0717731\ttotal: 46.1ms\tremaining: 163ms\n",
      "11:\tlearn: 0.0651714\ttotal: 50.2ms\tremaining: 159ms\n",
      "12:\tlearn: 0.0612724\ttotal: 54.2ms\tremaining: 154ms\n",
      "13:\tlearn: 0.0579029\ttotal: 58.1ms\tremaining: 150ms\n",
      "14:\tlearn: 0.0550868\ttotal: 62.6ms\tremaining: 146ms\n",
      "15:\tlearn: 0.0527577\ttotal: 66.7ms\tremaining: 142ms\n",
      "16:\tlearn: 0.0500489\ttotal: 71ms\tremaining: 138ms\n",
      "17:\tlearn: 0.0484955\ttotal: 75.1ms\tremaining: 134ms\n",
      "18:\tlearn: 0.0464129\ttotal: 79.1ms\tremaining: 129ms\n",
      "19:\tlearn: 0.0451733\ttotal: 83.3ms\tremaining: 125ms\n",
      "20:\tlearn: 0.0430626\ttotal: 87.6ms\tremaining: 121ms\n",
      "21:\tlearn: 0.0419861\ttotal: 91.6ms\tremaining: 117ms\n",
      "22:\tlearn: 0.0409962\ttotal: 95.9ms\tremaining: 113ms\n",
      "23:\tlearn: 0.0402492\ttotal: 99.9ms\tremaining: 108ms\n",
      "24:\tlearn: 0.0395628\ttotal: 104ms\tremaining: 104ms\n",
      "25:\tlearn: 0.0384495\ttotal: 109ms\tremaining: 100ms\n",
      "26:\tlearn: 0.0372597\ttotal: 113ms\tremaining: 96.4ms\n",
      "27:\tlearn: 0.0363117\ttotal: 117ms\tremaining: 92.3ms\n",
      "28:\tlearn: 0.0350286\ttotal: 122ms\tremaining: 88.2ms\n",
      "29:\tlearn: 0.0343711\ttotal: 126ms\tremaining: 84ms\n",
      "30:\tlearn: 0.0335296\ttotal: 130ms\tremaining: 79.7ms\n",
      "31:\tlearn: 0.0328861\ttotal: 134ms\tremaining: 75.5ms\n",
      "32:\tlearn: 0.0322709\ttotal: 138ms\tremaining: 71.2ms\n",
      "33:\tlearn: 0.0319336\ttotal: 143ms\tremaining: 67.1ms\n",
      "34:\tlearn: 0.0315868\ttotal: 147ms\tremaining: 62.8ms\n",
      "35:\tlearn: 0.0308836\ttotal: 151ms\tremaining: 58.8ms\n",
      "36:\tlearn: 0.0304226\ttotal: 156ms\tremaining: 54.8ms\n",
      "37:\tlearn: 0.0301078\ttotal: 160ms\tremaining: 50.6ms\n",
      "38:\tlearn: 0.0297475\ttotal: 165ms\tremaining: 46.4ms\n",
      "39:\tlearn: 0.0291508\ttotal: 169ms\tremaining: 42.2ms\n",
      "40:\tlearn: 0.0284268\ttotal: 173ms\tremaining: 38ms\n",
      "41:\tlearn: 0.0281901\ttotal: 177ms\tremaining: 33.8ms\n",
      "42:\tlearn: 0.0278785\ttotal: 182ms\tremaining: 29.6ms\n",
      "43:\tlearn: 0.0276474\ttotal: 186ms\tremaining: 25.3ms\n",
      "44:\tlearn: 0.0270742\ttotal: 190ms\tremaining: 21.1ms\n",
      "45:\tlearn: 0.0266379\ttotal: 194ms\tremaining: 16.9ms\n",
      "46:\tlearn: 0.0261947\ttotal: 199ms\tremaining: 12.7ms\n",
      "47:\tlearn: 0.0258494\ttotal: 203ms\tremaining: 8.45ms\n",
      "48:\tlearn: 0.0256344\ttotal: 207ms\tremaining: 4.22ms\n",
      "49:\tlearn: 0.0252216\ttotal: 212ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1e18e6ada00>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.datatypes._panel._convert import from_nested_to_2d_array\n",
    "\n",
    "\n",
    "cb2 = CatBoostClassifier(iterations=50,\n",
    "                         learning_rate=0.1)\n",
    "\n",
    "cb2.fit(from_nested_to_2d_array(train_X), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6893913043478261"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, cb2.predict(from_nested_to_2d_array(test_X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f76d4fda128b12615e46e0e8dd834a222e7abd956eb53de74309670d1db4104c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
