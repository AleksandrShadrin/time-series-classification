{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9',\n",
       "       ...\n",
       "       'X170', 'X171', 'X172', 'X173', 'X174', 'X175', 'X176', 'X177', 'X178',\n",
       "       'y'],\n",
       "      dtype='object', length=180)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Dataset.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "\n",
    "features = df.loc[:, \"X1\":'X178']\n",
    "features = from_2d_array_to_nested(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_transformer(label):\n",
    "    return 1 if label == 1 else 0\n",
    "\n",
    "labels = df['y'].apply(labels_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catch22(n_jobs=4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.transformations.panel.catch22 import Catch22\n",
    "\n",
    "ct22 = Catch22(n_jobs=4)\n",
    "ct22.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_22_train = ct22.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-10.300000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.140449</td>\n",
       "      <td>-0.162921</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>455.052410</td>\n",
       "      <td>0.073631</td>\n",
       "      <td>7.566146</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.920904</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.513737</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.071098</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>342.300018</td>\n",
       "      <td>223.349991</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>-0.168539</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>283737.533443</td>\n",
       "      <td>0.515418</td>\n",
       "      <td>481.433753</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.804044</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.700000</td>\n",
       "      <td>-20.650000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>-0.252809</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>996.198983</td>\n",
       "      <td>0.073631</td>\n",
       "      <td>10.907594</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.477048</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.099171</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.500000</td>\n",
       "      <td>-23.850000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>-0.449438</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1900.689483</td>\n",
       "      <td>0.171806</td>\n",
       "      <td>31.678487</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.730513</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.110178</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-34.400002</td>\n",
       "      <td>-25.300001</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.382022</td>\n",
       "      <td>-0.028090</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1924.504578</td>\n",
       "      <td>0.147262</td>\n",
       "      <td>17.006455</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.452505</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.098580</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1     2         3         4     5     6   \\\n",
       "0   -6.000000  -10.300000  49.0  0.140449 -0.162921  11.0  47.0   \n",
       "1  342.300018  223.349991  19.0  0.016854 -0.168539   3.0   6.0   \n",
       "2  -13.700000  -20.650000  47.0  0.359551 -0.252809  11.0  30.0   \n",
       "3  -13.500000  -23.850000  28.0  0.730337 -0.449438   4.0   6.0   \n",
       "4  -34.400002  -25.300001  23.0 -0.382022 -0.028090   7.0  15.0   \n",
       "\n",
       "              7         8           9   ...    12        13    14        15  \\\n",
       "0     455.052410  0.073631    7.566146  ...  23.0  0.920904  11.0  1.513737   \n",
       "1  283737.533443  0.515418  481.433753  ...   2.0  1.000000   9.0  1.804044   \n",
       "2     996.198983  0.073631   10.907594  ...  29.0  0.937853  10.0  1.477048   \n",
       "3    1900.689483  0.171806   31.678487  ...   5.0  0.954802   9.0  1.730513   \n",
       "4    1924.504578  0.147262   17.006455  ...   9.0  0.966102  16.0  1.452505   \n",
       "\n",
       "         16        17        18        19        20    21  \n",
       "0  0.208333  0.071098  0.853659  0.219512  0.006803   0.0  \n",
       "1  0.750000  0.110131  0.609756  0.219512  0.006371  11.0  \n",
       "2  0.171429  0.099171  0.804878  0.170732  0.080000   0.0  \n",
       "3  0.166667  0.110178  0.853659  0.195122  0.008230  10.0  \n",
       "4  0.700000  0.098580  0.487805  0.707317  0.004614  53.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_22_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform features by MINImally RandOm Convolutional KErnel Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.panel.rocket import MiniRocket\n",
    "\n",
    "mr = MiniRocket(num_kernels=1000, n_jobs=4)\n",
    "\n",
    "transformed_mr_train = mr.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>914</th>\n",
       "      <th>915</th>\n",
       "      <th>916</th>\n",
       "      <th>917</th>\n",
       "      <th>918</th>\n",
       "      <th>919</th>\n",
       "      <th>920</th>\n",
       "      <th>921</th>\n",
       "      <th>922</th>\n",
       "      <th>923</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477528</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.460674</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.376404</td>\n",
       "      <td>0.488235</td>\n",
       "      <td>0.488235</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.488764</td>\n",
       "      <td>0.443820</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477528</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.252809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535294</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.347059</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.443820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.174157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570588</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.623595</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.455056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.544944</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 924 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.028090  1.000000  0.000000  0.676471  1.000000  0.176471  0.713483   \n",
       "1  0.460674  0.573034  0.376404  0.488235  0.488235  0.482353  0.488764   \n",
       "2  0.106742  1.000000  0.000000  0.552941  0.970588  0.205882  0.595506   \n",
       "3  0.252809  1.000000  0.000000  0.535294  0.788235  0.347059  0.573034   \n",
       "4  0.174157  1.000000  0.000000  0.570588  0.876471  0.329412  0.623595   \n",
       "\n",
       "        7         8         9    ...       914  915       916  917       918  \\\n",
       "0  0.000000  0.410112  1.000000  ...  0.685393  1.0  0.505618  0.0  0.000000   \n",
       "1  0.443820  0.483146  0.623529  ...  0.522472  1.0  0.528090  1.0  0.477528   \n",
       "2  0.000000  0.331461  1.000000  ...  0.640449  1.0  0.685393  0.0  0.000000   \n",
       "3  0.016854  0.443820  1.000000  ...  0.657303  1.0  0.556180  1.0  0.044944   \n",
       "4  0.016854  0.455056  1.000000  ...  0.646067  1.0  0.438202  0.0  0.016854   \n",
       "\n",
       "   919       920  921       922  923  \n",
       "0  0.0  1.000000  0.0  0.477528  1.0  \n",
       "1  0.5  0.550562  0.0  0.494382  1.0  \n",
       "2  0.0  0.887640  1.0  0.747191  1.0  \n",
       "3  1.0  0.932584  0.0  0.713483  1.0  \n",
       "4  0.0  0.926966  1.0  0.544944  1.0  \n",
       "\n",
       "[5 rows x 924 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_mr_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rc = RandomForestClassifier(n_estimators=1000)\n",
    "rc.fit(transformed_22_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_22_test = ct22.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983304347826087"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, rc.predict(transformed_22_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4809019\ttotal: 224ms\tremaining: 11s\n",
      "1:\tlearn: 0.3302361\ttotal: 229ms\tremaining: 5.49s\n",
      "2:\tlearn: 0.2665176\ttotal: 233ms\tremaining: 3.65s\n",
      "3:\tlearn: 0.2228918\ttotal: 237ms\tremaining: 2.72s\n",
      "4:\tlearn: 0.1686958\ttotal: 241ms\tremaining: 2.17s\n",
      "5:\tlearn: 0.1382185\ttotal: 246ms\tremaining: 1.8s\n",
      "6:\tlearn: 0.1093829\ttotal: 249ms\tremaining: 1.53s\n",
      "7:\tlearn: 0.0980791\ttotal: 254ms\tremaining: 1.33s\n",
      "8:\tlearn: 0.0852446\ttotal: 258ms\tremaining: 1.18s\n",
      "9:\tlearn: 0.0763056\ttotal: 263ms\tremaining: 1.05s\n",
      "10:\tlearn: 0.0689818\ttotal: 268ms\tremaining: 949ms\n",
      "11:\tlearn: 0.0621849\ttotal: 272ms\tremaining: 860ms\n",
      "12:\tlearn: 0.0573800\ttotal: 276ms\tremaining: 787ms\n",
      "13:\tlearn: 0.0549828\ttotal: 281ms\tremaining: 723ms\n",
      "14:\tlearn: 0.0528779\ttotal: 285ms\tremaining: 666ms\n",
      "15:\tlearn: 0.0498300\ttotal: 290ms\tremaining: 616ms\n",
      "16:\tlearn: 0.0468018\ttotal: 294ms\tremaining: 571ms\n",
      "17:\tlearn: 0.0452882\ttotal: 298ms\tremaining: 530ms\n",
      "18:\tlearn: 0.0434052\ttotal: 303ms\tremaining: 495ms\n",
      "19:\tlearn: 0.0420770\ttotal: 308ms\tremaining: 461ms\n",
      "20:\tlearn: 0.0408984\ttotal: 312ms\tremaining: 430ms\n",
      "21:\tlearn: 0.0402464\ttotal: 316ms\tremaining: 402ms\n",
      "22:\tlearn: 0.0388831\ttotal: 321ms\tremaining: 376ms\n",
      "23:\tlearn: 0.0377731\ttotal: 325ms\tremaining: 352ms\n",
      "24:\tlearn: 0.0368962\ttotal: 329ms\tremaining: 329ms\n",
      "25:\tlearn: 0.0360800\ttotal: 334ms\tremaining: 308ms\n",
      "26:\tlearn: 0.0351107\ttotal: 338ms\tremaining: 288ms\n",
      "27:\tlearn: 0.0346688\ttotal: 342ms\tremaining: 269ms\n",
      "28:\tlearn: 0.0342258\ttotal: 347ms\tremaining: 251ms\n",
      "29:\tlearn: 0.0335547\ttotal: 351ms\tremaining: 234ms\n",
      "30:\tlearn: 0.0326881\ttotal: 356ms\tremaining: 218ms\n",
      "31:\tlearn: 0.0321730\ttotal: 360ms\tremaining: 202ms\n",
      "32:\tlearn: 0.0315100\ttotal: 364ms\tremaining: 188ms\n",
      "33:\tlearn: 0.0313150\ttotal: 369ms\tremaining: 174ms\n",
      "34:\tlearn: 0.0308208\ttotal: 373ms\tremaining: 160ms\n",
      "35:\tlearn: 0.0302499\ttotal: 378ms\tremaining: 147ms\n",
      "36:\tlearn: 0.0297451\ttotal: 382ms\tremaining: 134ms\n",
      "37:\tlearn: 0.0294391\ttotal: 386ms\tremaining: 122ms\n",
      "38:\tlearn: 0.0287427\ttotal: 390ms\tremaining: 110ms\n",
      "39:\tlearn: 0.0281076\ttotal: 394ms\tremaining: 98.6ms\n",
      "40:\tlearn: 0.0277997\ttotal: 399ms\tremaining: 87.6ms\n",
      "41:\tlearn: 0.0274796\ttotal: 403ms\tremaining: 76.8ms\n",
      "42:\tlearn: 0.0271815\ttotal: 408ms\tremaining: 66.4ms\n",
      "43:\tlearn: 0.0269231\ttotal: 412ms\tremaining: 56.2ms\n",
      "44:\tlearn: 0.0266644\ttotal: 417ms\tremaining: 46.3ms\n",
      "45:\tlearn: 0.0261745\ttotal: 421ms\tremaining: 36.6ms\n",
      "46:\tlearn: 0.0256453\ttotal: 425ms\tremaining: 27.1ms\n",
      "47:\tlearn: 0.0254552\ttotal: 430ms\tremaining: 17.9ms\n",
      "48:\tlearn: 0.0252595\ttotal: 434ms\tremaining: 8.86ms\n",
      "49:\tlearn: 0.0248646\ttotal: 439ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x194dbeb9460>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cb = CatBoostClassifier(iterations=50,\n",
    "                        learning_rate=0.1)\n",
    "\n",
    "cb.fit(transformed_22_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9829565217391304"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, cb.predict(transformed_22_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    dense_layer = keras.layers.Dense(256, activation=\"relu\")(input_layer)\n",
    "    \n",
    "    dense_layer = keras.layers.Dense(128, activation=\"relu\")(dense_layer)\n",
    "\n",
    "    dense_layer = keras.layers.Dense(32, activation=\"relu\")(dense_layer)\n",
    "    \n",
    "    output_layer = keras.layers.Dense(2, activation=\"softmax\")(dense_layer)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model = make_model(input_shape=transformed_22_train.iloc[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 496.4676 - sparse_categorical_accuracy: 0.7081 - val_loss: 658.5109 - val_sparse_categorical_accuracy: 0.8157 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337.9225 - sparse_categorical_accuracy: 0.7826 - val_loss: 322.3779 - val_sparse_categorical_accuracy: 0.9084 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 270.8577 - sparse_categorical_accuracy: 0.8394 - val_loss: 288.6060 - val_sparse_categorical_accuracy: 0.7849 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 104.3252 - sparse_categorical_accuracy: 0.8787 - val_loss: 71.7020 - val_sparse_categorical_accuracy: 0.9304 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 152.4017 - sparse_categorical_accuracy: 0.8816 - val_loss: 176.7410 - val_sparse_categorical_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 110.7391 - sparse_categorical_accuracy: 0.8968 - val_loss: 912.3643 - val_sparse_categorical_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 172.9026 - sparse_categorical_accuracy: 0.9001 - val_loss: 217.5048 - val_sparse_categorical_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 111.2452 - sparse_categorical_accuracy: 0.9157 - val_loss: 505.7653 - val_sparse_categorical_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.4997 - sparse_categorical_accuracy: 0.8107 - val_loss: 469.9417 - val_sparse_categorical_accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 314.6643 - sparse_categorical_accuracy: 0.8942 - val_loss: 428.1380 - val_sparse_categorical_accuracy: 0.9432 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 89.9210 - sparse_categorical_accuracy: 0.9186 - val_loss: 793.1163 - val_sparse_categorical_accuracy: 0.9299 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 244.5598 - sparse_categorical_accuracy: 0.8926 - val_loss: 315.3218 - val_sparse_categorical_accuracy: 0.8475 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 214.6489 - sparse_categorical_accuracy: 0.8713 - val_loss: 159.3083 - val_sparse_categorical_accuracy: 0.9194 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 52.7580 - sparse_categorical_accuracy: 0.9306 - val_loss: 103.1023 - val_sparse_categorical_accuracy: 0.9426 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 28.6316 - sparse_categorical_accuracy: 0.9313 - val_loss: 225.4903 - val_sparse_categorical_accuracy: 0.9264 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 54.4535 - sparse_categorical_accuracy: 0.9320 - val_loss: 39.4223 - val_sparse_categorical_accuracy: 0.9165 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 20.1104 - sparse_categorical_accuracy: 0.9401 - val_loss: 36.4355 - val_sparse_categorical_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 24.2684 - sparse_categorical_accuracy: 0.9275 - val_loss: 19.0802 - val_sparse_categorical_accuracy: 0.9322 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 29.8689 - sparse_categorical_accuracy: 0.9206 - val_loss: 152.6373 - val_sparse_categorical_accuracy: 0.9264 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 32.7897 - sparse_categorical_accuracy: 0.9307 - val_loss: 39.6374 - val_sparse_categorical_accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 74.3610 - sparse_categorical_accuracy: 0.8925 - val_loss: 77.5334 - val_sparse_categorical_accuracy: 0.9287 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 43.2256 - sparse_categorical_accuracy: 0.9400 - val_loss: 74.2220 - val_sparse_categorical_accuracy: 0.9223 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 18.8703 - sparse_categorical_accuracy: 0.9436 - val_loss: 3.2035 - val_sparse_categorical_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5.5849 - sparse_categorical_accuracy: 0.9509 - val_loss: 7.2210 - val_sparse_categorical_accuracy: 0.9443 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2.6754 - sparse_categorical_accuracy: 0.9481 - val_loss: 9.0425 - val_sparse_categorical_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.8256 - sparse_categorical_accuracy: 0.9519 - val_loss: 9.5911 - val_sparse_categorical_accuracy: 0.9357 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.5274 - sparse_categorical_accuracy: 0.9504 - val_loss: 9.9106 - val_sparse_categorical_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.3052 - sparse_categorical_accuracy: 0.9490 - val_loss: 9.9646 - val_sparse_categorical_accuracy: 0.9443 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1946 - sparse_categorical_accuracy: 0.9499 - val_loss: 9.9953 - val_sparse_categorical_accuracy: 0.9403 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1682 - sparse_categorical_accuracy: 0.9484 - val_loss: 9.9412 - val_sparse_categorical_accuracy: 0.9380 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1696 - sparse_categorical_accuracy: 0.9486 - val_loss: 10.0086 - val_sparse_categorical_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1469 - sparse_categorical_accuracy: 0.9499 - val_loss: 10.0065 - val_sparse_categorical_accuracy: 0.9501 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9483 - val_loss: 10.0529 - val_sparse_categorical_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1420 - sparse_categorical_accuracy: 0.9503 - val_loss: 10.0913 - val_sparse_categorical_accuracy: 0.9154 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1506 - sparse_categorical_accuracy: 0.9487 - val_loss: 10.1171 - val_sparse_categorical_accuracy: 0.9455 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9477 - val_loss: 10.0923 - val_sparse_categorical_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1353 - sparse_categorical_accuracy: 0.9516 - val_loss: 10.1119 - val_sparse_categorical_accuracy: 0.9374 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1348 - sparse_categorical_accuracy: 0.9465 - val_loss: 10.1692 - val_sparse_categorical_accuracy: 0.9432 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9483 - val_loss: 10.1440 - val_sparse_categorical_accuracy: 0.9397 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1359 - sparse_categorical_accuracy: 0.9477 - val_loss: 10.1297 - val_sparse_categorical_accuracy: 0.9432 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1329 - sparse_categorical_accuracy: 0.9487 - val_loss: 10.2422 - val_sparse_categorical_accuracy: 0.9414 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1264 - sparse_categorical_accuracy: 0.9493 - val_loss: 10.1722 - val_sparse_categorical_accuracy: 0.9478 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1290 - sparse_categorical_accuracy: 0.9501 - val_loss: 10.1697 - val_sparse_categorical_accuracy: 0.9449 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9510 - val_loss: 10.2786 - val_sparse_categorical_accuracy: 0.9443 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1179 - sparse_categorical_accuracy: 0.9522 - val_loss: 10.2387 - val_sparse_categorical_accuracy: 0.9432 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1160 - sparse_categorical_accuracy: 0.9514 - val_loss: 10.3820 - val_sparse_categorical_accuracy: 0.9316 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1163 - sparse_categorical_accuracy: 0.9486 - val_loss: 10.4613 - val_sparse_categorical_accuracy: 0.9461 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1153 - sparse_categorical_accuracy: 0.9507 - val_loss: 10.2753 - val_sparse_categorical_accuracy: 0.9443 - lr: 5.0000e-04\n",
      "Epoch 49/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9499 - val_loss: 10.2976 - val_sparse_categorical_accuracy: 0.9443 - lr: 5.0000e-04\n",
      "Epoch 50/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9507 - val_loss: 10.1937 - val_sparse_categorical_accuracy: 0.9409 - lr: 5.0000e-04\n",
      "Epoch 51/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9490 - val_loss: 10.2944 - val_sparse_categorical_accuracy: 0.9461 - lr: 5.0000e-04\n",
      "Epoch 52/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1172 - sparse_categorical_accuracy: 0.9493 - val_loss: 10.3578 - val_sparse_categorical_accuracy: 0.9472 - lr: 5.0000e-04\n",
      "Epoch 53/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1123 - sparse_categorical_accuracy: 0.9483 - val_loss: 9.5867 - val_sparse_categorical_accuracy: 0.9507 - lr: 5.0000e-04\n",
      "Epoch 54/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9451 - val_loss: 9.8623 - val_sparse_categorical_accuracy: 0.9467 - lr: 5.0000e-04\n",
      "Epoch 55/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9467 - val_loss: 9.9384 - val_sparse_categorical_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 56/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1204 - sparse_categorical_accuracy: 0.9490 - val_loss: 9.8844 - val_sparse_categorical_accuracy: 0.9113 - lr: 5.0000e-04\n",
      "Epoch 57/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1844 - sparse_categorical_accuracy: 0.9109 - val_loss: 7.5222 - val_sparse_categorical_accuracy: 0.9217 - lr: 5.0000e-04\n",
      "Epoch 58/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.2008 - sparse_categorical_accuracy: 0.9226 - val_loss: 6.8214 - val_sparse_categorical_accuracy: 0.9241 - lr: 5.0000e-04\n",
      "Epoch 59/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1436 - sparse_categorical_accuracy: 0.9332 - val_loss: 7.9173 - val_sparse_categorical_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9397 - val_loss: 7.8943 - val_sparse_categorical_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9491 - val_loss: 7.8461 - val_sparse_categorical_accuracy: 0.9496 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1160 - sparse_categorical_accuracy: 0.9438 - val_loss: 8.4868 - val_sparse_categorical_accuracy: 0.9426 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1459 - sparse_categorical_accuracy: 0.9461 - val_loss: 4.5862 - val_sparse_categorical_accuracy: 0.9096 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1128 - sparse_categorical_accuracy: 0.9454 - val_loss: 3.7870 - val_sparse_categorical_accuracy: 0.9478 - lr: 2.5000e-04\n",
      "Epoch 65/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9533 - val_loss: 2.3047 - val_sparse_categorical_accuracy: 0.9449 - lr: 2.5000e-04\n",
      "Epoch 66/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.1057 - sparse_categorical_accuracy: 0.9530 - val_loss: 2.1734 - val_sparse_categorical_accuracy: 0.9472 - lr: 2.5000e-04\n",
      "Epoch 67/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1046 - sparse_categorical_accuracy: 0.9536 - val_loss: 1.5678 - val_sparse_categorical_accuracy: 0.9403 - lr: 2.5000e-04\n",
      "Epoch 68/200\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1617 - val_sparse_categorical_accuracy: 0.9449 - lr: 2.5000e-04\n",
      "Epoch 69/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1047 - sparse_categorical_accuracy: 0.9562 - val_loss: 0.2241 - val_sparse_categorical_accuracy: 0.9490 - lr: 2.5000e-04\n",
      "Epoch 70/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.4212 - val_sparse_categorical_accuracy: 0.9501 - lr: 2.5000e-04\n",
      "Epoch 71/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1020 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.3571 - val_sparse_categorical_accuracy: 0.9467 - lr: 2.5000e-04\n",
      "Epoch 72/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1013 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.3838 - val_sparse_categorical_accuracy: 0.9507 - lr: 2.5000e-04\n",
      "Epoch 73/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1051 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.4098 - val_sparse_categorical_accuracy: 0.9478 - lr: 2.5000e-04\n",
      "Epoch 74/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.6394 - val_sparse_categorical_accuracy: 0.9496 - lr: 2.5000e-04\n",
      "Epoch 75/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1050 - sparse_categorical_accuracy: 0.9528 - val_loss: 1.0933 - val_sparse_categorical_accuracy: 0.9478 - lr: 2.5000e-04\n",
      "Epoch 76/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1038 - sparse_categorical_accuracy: 0.9546 - val_loss: 0.7399 - val_sparse_categorical_accuracy: 0.9484 - lr: 2.5000e-04\n",
      "Epoch 77/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1036 - sparse_categorical_accuracy: 0.9558 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9420 - lr: 2.5000e-04\n",
      "Epoch 78/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5803 - val_sparse_categorical_accuracy: 0.9530 - lr: 2.5000e-04\n",
      "Epoch 79/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1024 - sparse_categorical_accuracy: 0.9541 - val_loss: 1.2793 - val_sparse_categorical_accuracy: 0.9438 - lr: 2.5000e-04\n",
      "Epoch 80/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9520 - val_loss: 1.6454 - val_sparse_categorical_accuracy: 0.9507 - lr: 2.5000e-04\n",
      "Epoch 81/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1724 - val_sparse_categorical_accuracy: 0.9496 - lr: 2.5000e-04\n",
      "Epoch 82/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9536 - val_loss: 0.5594 - val_sparse_categorical_accuracy: 0.9397 - lr: 2.5000e-04\n",
      "Epoch 83/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1058 - sparse_categorical_accuracy: 0.9543 - val_loss: 0.7292 - val_sparse_categorical_accuracy: 0.9461 - lr: 2.5000e-04\n",
      "Epoch 84/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9516 - val_loss: 1.7226 - val_sparse_categorical_accuracy: 0.9449 - lr: 2.5000e-04\n",
      "Epoch 85/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9523 - val_loss: 1.7435 - val_sparse_categorical_accuracy: 0.9478 - lr: 2.5000e-04\n",
      "Epoch 86/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9510 - val_loss: 1.1990 - val_sparse_categorical_accuracy: 0.9461 - lr: 2.5000e-04\n",
      "Epoch 87/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.1694 - val_sparse_categorical_accuracy: 0.9455 - lr: 2.5000e-04\n",
      "Epoch 88/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1033 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.9994 - val_sparse_categorical_accuracy: 0.9113 - lr: 2.5000e-04\n",
      "Epoch 89/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9533 - val_loss: 1.0653 - val_sparse_categorical_accuracy: 0.9420 - lr: 1.2500e-04\n",
      "Epoch 90/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0969 - sparse_categorical_accuracy: 0.9577 - val_loss: 1.2218 - val_sparse_categorical_accuracy: 0.9472 - lr: 1.2500e-04\n",
      "Epoch 91/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9581 - val_loss: 1.5649 - val_sparse_categorical_accuracy: 0.9461 - lr: 1.2500e-04\n",
      "Epoch 92/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9584 - val_loss: 1.1615 - val_sparse_categorical_accuracy: 0.9472 - lr: 1.2500e-04\n",
      "Epoch 93/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9438 - lr: 1.2500e-04\n",
      "Epoch 94/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0944 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.9519 - lr: 1.2500e-04\n",
      "Epoch 95/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0963 - sparse_categorical_accuracy: 0.9578 - val_loss: 0.4595 - val_sparse_categorical_accuracy: 0.9420 - lr: 1.2500e-04\n",
      "Epoch 96/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9594 - val_loss: 0.2908 - val_sparse_categorical_accuracy: 0.9472 - lr: 1.2500e-04\n",
      "Epoch 97/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9581 - val_loss: 2.6715 - val_sparse_categorical_accuracy: 0.9467 - lr: 1.2500e-04\n",
      "Epoch 98/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0978 - sparse_categorical_accuracy: 0.9567 - val_loss: 1.0213 - val_sparse_categorical_accuracy: 0.9496 - lr: 1.2500e-04\n",
      "Epoch 99/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9577 - val_loss: 1.6726 - val_sparse_categorical_accuracy: 0.9501 - lr: 1.2500e-04\n",
      "Epoch 100/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.9157 - val_sparse_categorical_accuracy: 0.9507 - lr: 1.2500e-04\n",
      "Epoch 101/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9572 - val_loss: 0.8819 - val_sparse_categorical_accuracy: 0.9490 - lr: 1.2500e-04\n",
      "Epoch 102/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9565 - val_loss: 1.4282 - val_sparse_categorical_accuracy: 0.9478 - lr: 1.2500e-04\n",
      "Epoch 103/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0915 - sparse_categorical_accuracy: 0.9600 - val_loss: 2.6607 - val_sparse_categorical_accuracy: 0.9455 - lr: 1.2500e-04\n",
      "Epoch 104/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9574 - val_loss: 1.1522 - val_sparse_categorical_accuracy: 0.9519 - lr: 1.2500e-04\n",
      "Epoch 105/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0963 - sparse_categorical_accuracy: 0.9562 - val_loss: 1.5958 - val_sparse_categorical_accuracy: 0.9501 - lr: 1.2500e-04\n",
      "Epoch 106/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.9461 - lr: 1.2500e-04\n",
      "Epoch 107/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.7419 - val_sparse_categorical_accuracy: 0.9507 - lr: 1.2500e-04\n",
      "Epoch 108/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.5971 - val_sparse_categorical_accuracy: 0.9519 - lr: 1.2500e-04\n",
      "Epoch 109/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9610 - val_loss: 0.7236 - val_sparse_categorical_accuracy: 0.9461 - lr: 1.0000e-04\n",
      "Epoch 110/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9577 - val_loss: 1.0889 - val_sparse_categorical_accuracy: 0.9507 - lr: 1.0000e-04\n",
      "Epoch 111/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9601 - val_loss: 1.1579 - val_sparse_categorical_accuracy: 0.9513 - lr: 1.0000e-04\n",
      "Epoch 112/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0915 - sparse_categorical_accuracy: 0.9584 - val_loss: 1.1323 - val_sparse_categorical_accuracy: 0.9554 - lr: 1.0000e-04\n",
      "Epoch 113/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.9498 - val_sparse_categorical_accuracy: 0.9525 - lr: 1.0000e-04\n",
      "Epoch 114/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9616 - val_loss: 0.8440 - val_sparse_categorical_accuracy: 0.9501 - lr: 1.0000e-04\n",
      "Epoch 115/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9564 - val_loss: 0.9589 - val_sparse_categorical_accuracy: 0.9490 - lr: 1.0000e-04\n",
      "Epoch 116/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9597 - val_loss: 1.6243 - val_sparse_categorical_accuracy: 0.9530 - lr: 1.0000e-04\n",
      "Epoch 117/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9577 - val_loss: 0.7034 - val_sparse_categorical_accuracy: 0.9461 - lr: 1.0000e-04\n",
      "Epoch 118/200\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9594 - val_loss: 1.6899 - val_sparse_categorical_accuracy: 0.9513 - lr: 1.0000e-04\n",
      "Epoch 118: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    transformed_22_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 955us/step - loss: 2.7181 - sparse_categorical_accuracy: 0.9537\n",
      "Test accuracy 0.9537391066551208\n",
      "Test loss 2.7180848121643066\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_model.h5\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(transformed_22_test, y_test)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MiniRocket transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_mr_test = mr.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "rfc.fit(transformed_mr_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853913043478261"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, rfc.predict(transformed_mr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4619851\ttotal: 36.3ms\tremaining: 1.78s\n",
      "1:\tlearn: 0.3477541\ttotal: 78.2ms\tremaining: 1.88s\n",
      "2:\tlearn: 0.2584965\ttotal: 110ms\tremaining: 1.72s\n",
      "3:\tlearn: 0.1870093\ttotal: 142ms\tremaining: 1.64s\n",
      "4:\tlearn: 0.1448217\ttotal: 177ms\tremaining: 1.59s\n",
      "5:\tlearn: 0.1164832\ttotal: 212ms\tremaining: 1.55s\n",
      "6:\tlearn: 0.0949558\ttotal: 246ms\tremaining: 1.51s\n",
      "7:\tlearn: 0.0812881\ttotal: 283ms\tremaining: 1.48s\n",
      "8:\tlearn: 0.0720234\ttotal: 322ms\tremaining: 1.46s\n",
      "9:\tlearn: 0.0640147\ttotal: 357ms\tremaining: 1.43s\n",
      "10:\tlearn: 0.0570303\ttotal: 392ms\tremaining: 1.39s\n",
      "11:\tlearn: 0.0516095\ttotal: 426ms\tremaining: 1.35s\n",
      "12:\tlearn: 0.0479761\ttotal: 459ms\tremaining: 1.31s\n",
      "13:\tlearn: 0.0443297\ttotal: 495ms\tremaining: 1.27s\n",
      "14:\tlearn: 0.0413124\ttotal: 530ms\tremaining: 1.24s\n",
      "15:\tlearn: 0.0394240\ttotal: 565ms\tremaining: 1.2s\n",
      "16:\tlearn: 0.0375479\ttotal: 612ms\tremaining: 1.19s\n",
      "17:\tlearn: 0.0361016\ttotal: 643ms\tremaining: 1.14s\n",
      "18:\tlearn: 0.0351825\ttotal: 672ms\tremaining: 1.1s\n",
      "19:\tlearn: 0.0338705\ttotal: 703ms\tremaining: 1.05s\n",
      "20:\tlearn: 0.0328507\ttotal: 732ms\tremaining: 1.01s\n",
      "21:\tlearn: 0.0323711\ttotal: 765ms\tremaining: 974ms\n",
      "22:\tlearn: 0.0306474\ttotal: 798ms\tremaining: 936ms\n",
      "23:\tlearn: 0.0300516\ttotal: 828ms\tremaining: 897ms\n",
      "24:\tlearn: 0.0297898\ttotal: 857ms\tremaining: 857ms\n",
      "25:\tlearn: 0.0296083\ttotal: 885ms\tremaining: 817ms\n",
      "26:\tlearn: 0.0295357\ttotal: 914ms\tremaining: 778ms\n",
      "27:\tlearn: 0.0286148\ttotal: 946ms\tremaining: 744ms\n",
      "28:\tlearn: 0.0285732\ttotal: 974ms\tremaining: 706ms\n",
      "29:\tlearn: 0.0275027\ttotal: 1s\tremaining: 671ms\n",
      "30:\tlearn: 0.0270169\ttotal: 1.04s\tremaining: 637ms\n",
      "31:\tlearn: 0.0262616\ttotal: 1.07s\tremaining: 602ms\n",
      "32:\tlearn: 0.0252395\ttotal: 1.1s\tremaining: 568ms\n",
      "33:\tlearn: 0.0248860\ttotal: 1.13s\tremaining: 533ms\n",
      "34:\tlearn: 0.0241164\ttotal: 1.17s\tremaining: 500ms\n",
      "35:\tlearn: 0.0238820\ttotal: 1.2s\tremaining: 466ms\n",
      "36:\tlearn: 0.0238434\ttotal: 1.23s\tremaining: 433ms\n",
      "37:\tlearn: 0.0237003\ttotal: 1.27s\tremaining: 401ms\n",
      "38:\tlearn: 0.0236547\ttotal: 1.31s\tremaining: 369ms\n",
      "39:\tlearn: 0.0235844\ttotal: 1.34s\tremaining: 335ms\n",
      "40:\tlearn: 0.0230657\ttotal: 1.37s\tremaining: 302ms\n",
      "41:\tlearn: 0.0230349\ttotal: 1.41s\tremaining: 269ms\n",
      "42:\tlearn: 0.0228175\ttotal: 1.44s\tremaining: 235ms\n",
      "43:\tlearn: 0.0226000\ttotal: 1.5s\tremaining: 205ms\n",
      "44:\tlearn: 0.0224780\ttotal: 1.54s\tremaining: 171ms\n",
      "45:\tlearn: 0.0223081\ttotal: 1.57s\tremaining: 137ms\n",
      "46:\tlearn: 0.0221061\ttotal: 1.6s\tremaining: 102ms\n",
      "47:\tlearn: 0.0213016\ttotal: 1.63s\tremaining: 68.1ms\n",
      "48:\tlearn: 0.0211527\ttotal: 1.66s\tremaining: 34ms\n",
      "49:\tlearn: 0.0206570\ttotal: 1.71s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x194f07bfcd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb2 = CatBoostClassifier(iterations=50,\n",
    "                         learning_rate=0.1)\n",
    "\n",
    "cb2.fit(transformed_mr_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983304347826087"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, cb2.predict(transformed_mr_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f76d4fda128b12615e46e0e8dd834a222e7abd956eb53de74309670d1db4104c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
